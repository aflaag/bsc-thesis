\chapter{Discussion} \label{chap:discussion}

This last chapter provides a discussion of the studies presented, evaluating their methodologies, considering additional aspects not previously addressed, and reviewing the quality of their written presentation.

\section{Dendrix}

\subsection{The deterministic formalization}

\textcite{dendrix} provided one of the first \textbf{mathematical formalizations} of the phenomena of \textit{mutual exclusivity} and \textit{coverage}, in the context of gene mutations. Specifically, the definitions introduced offer a very \textit{intuitive approach} to formalizing these biological concepts:

\begin{itemize}
    \item the \textbf{coverage of a gene} is defined as the set of patients exhibiting a mutation of that gene, equivalent to the number of 1s in its column of the mutation matrix;
    \item a set of genes is defined to be \textbf{mutually exclusive} if no patient has more than one mutated gene in the set, i.e. no row of the set's associated submatrix has more than 1 one;
    \item the \textbf{coverage of a gene} set is the set of patients with at least one mutation in the set;
    \item the \textbf{coverage overlap} of a gene set is the count of patients who possess more than one mutation within the gene set;
    \item the \textbf{weight} of a gene set is calculated as the difference between the \textit{coverage} of the gene set and its \textit{coverage overlap}.
\end{itemize}

Consequently, a \textbf{higher weight} for a gene set indicates both \textit{greater coverage} and \textit{mutual exclusivity} among its genes. The weight formula suggests that the \textbf{optimal gene set}, i.e. the one that maximizes its weight, is the one where the associated matrix has a high number of rows with at least one 1, and a minimal number of rows with more than one 1.

This metric stands out as one of the most \textit{elegant} among those discussed in this work, offering both a clear and intuitive measure, along with a straightforward formula. Although their metric may appear to oversimplify the complexity of identifying driver pathways --- since mutual exclusivity alone does not capture all aspects of pathway analysis, and \textit{exact mutual exclusivity} is rarely observed in real data --- it remains a widely accepted deterministic formalization. Numerous studies, including those referenced in this work, suggest that this measure represents one of the most refined approaches currently available.

\subsection{Additional considerations}

The work of \textcite{dendrix} is precise and methodical, and the mathematical analysis is also thorough and well-supported. The supplemental material includes extensive proofs, such as the \NPHard-ness of the MWSP (provided in \cref{mwsp proof}), the correctness of their \textit{greedy algorithm}, and the rapid mixing property of their MCMC approach. The clarity of this presentation greatly facilitates the understanding of the study and stands out compared to other papers analyzed, which often lack this level of explanation, as discussed in subsequent sections.

As a final note, conducting a comparative analysis between the MCMC approach and a \href{https://en.wikipedia.org/wiki/Random_search}{random search} method would be interesting. For instance, consider the following algorithm:

\begin{enumerate}
    \item \textit{initialization}: given the set of all genes $\mathcal G$, choose an arbitrary subset $M_0 \subseteq \mathcal G$ of $k$ genes;
    \item \textit{iteration}: for $t = 1, 2, \ldots$ derive $M_{t + 1}$ from $M_t$ as follows:

    \begin{enumerate}
        \item define $W \subseteq \mathcal G$ and $V \subseteq M_t$ randomly;
        \item choose $\displaystyle (\hat w, \hat v) \in \argmax_{(w, v) \in W \times V}{W\rbk{\rbk{M_t - \{v\}} \cup \{w\}}}$;
        \item set $M_{t + 1} := \rbk{M_t - \{\hat v\}} \cup \{\hat w\}$.
    \end{enumerate}
\end{enumerate}

At each step, this algorithm selects a predetermined amount of \textit{random adjustments}, choosing the one that \textit{maximizes the weight} as the base set for the next iteration. It would be interesting to evaluate how this approach performs on real data, and whether the MCMC algorithm outperforms it.

\section{Multi-Dendrix}

\subsection{The ILP of Dendrix}

\textcite{multi-dendrix} formulated the MWSP as an ILP, which offers a more intuitive and \textit{natural approach} to the problem. However, as highlighted by several authors, the set $M$ that maximizes $W(M)$ may not always represent an \textit{actual biological driver pathway}. This limitation stems from the fact that exact mutual exclusivity and coverage are rarely observed in real mutation data, making exact solutions to the MWSP potentially unrealistic. Therefore, a more \textbf{statistical approach} or a probabilistic method, such as the MCMC algorithm used by \textcite{dendrix}, may offer more reliable results in certain contexts.

\subsection{The ILP of Multi-Dendrix}

The ILP formulation for the \textbf{simultaneous identification} of multiple driver pathways is a \textit{natural extension} of Dendrix's ILP. However, it may face the same challenge in that optimal solutions might not correspond to \textit{actual biological pathways}. Moreover, \textcite{multi-dendrix} highlight that while the ILP used in Multi-Dendrix effectively finds optimal solutions, it does not rigorously explore \textit{suboptimal ones}, in contrast with the MCMC approach, which samples them based on their weight.

Additionally, the weight function $W'(M)$ in Multi-Dendrix does not explicitly account for the \textbf{co-occurrence of mutations} between genes in different sets. Instead, it prioritizes gene sets with high coverage and approximate exclusivity, which may lead to co-occurrence due to high coverage alone (e.g. when all gene sets have full coverage). Given that co-occurrence is crucial in large biological pathways, algorithms that optimize for gene sets where mutations frequently co-occur might be more effective in identifying key components of these pathways \cite{multi-dendrix}.

Lastly, it is worth emphasizing that, according to survey studies \cite{survey}, this approach remains one of the fastest --- due to the efficiency of ILP solvers --- and performs exceptionally well.

\subsection{Additional considerations}

As a final note, their exposition of the ILP of Multi-Dendrix lacks clarity and precision. Specifically, in \textit{their} definition of the MMWSP, each set in the collection is of size exactly $m \times k$ for a \textit{fixed} $k$. However, the ILP formulation \textit{they originally provided} does not include any equation defining the sizes of the sets in the collection. Based on the context, it seems likely that the intention was for each gene set to have a variable size, ranging between $k_\mathrm{min}$ and $k_\mathrm{max}$. In general, such a discrepancy could potentially raise concerns regarding \textbf{time complexity}, a critical consideration given the \textit{large-scale data} typical in this field.

\section{MDPFinder}

\subsection{The ILP of Dendrix}

To solve the MWSP, \textcite{mdpfinder} formulated an ILP that is identical in the formulation and constraints to the one proposed by \textcite{multi-dendrix}. Although the MDPFinder paper was published in 2012 and the Multi-Dendrix paper in 2013, the latter does not reference the work of \textcite{mdpfinder}, and both studies present the ILP formulation of Dendrix as their own innovation. For greater clarity and more detailed definitions of the indicator variables, in this work, the formulation was attributed to \textcite{multi-dendrix}, because their presentation of the MWSP's ILP was clearer compared to that of \textcite{mdpfinder}.

\subsection{The genetic algorithm}

Genetic algorithms offer a \textit{flexible} and intuitive framework for exploration and optimization. However, a significant drawback is their relatively \textbf{slow performance} compared to other methods. In fact, as noted by \textcite{mdpfinder}, their genetic algorithm is considerably slower than the alternatives they tested, being \textit{12 times slower} than the MCMC algorithm, and \textit{over 60 times slower} than the ILP.

Despite its undeniable slowness, the \textbf{versatility} of this approach is notable: it allows for easy modification of the objective function and offers a well-suited \textit{integration procedure} that may be challenging to incorporate into other algorithm types, such as the ILP. Additionally, the ability to explore suboptimal solutions is valuable, as shown in many findings reported in this work.

\section{Mutex}

\subsection{The statistical approach}

As mentioned in previous sections, a \textbf{statistical approach}, such as the one employed by \textcite{mutex}, appears to be the most suitable choice in this field, as \textit{exact mutual exclusivity} rarely occurs in nature. In fact, survey studies \cite{survey} indicate that this algorithm \textit{significantly outperforms} others in terms of both \href{https://en.wikipedia.org/wiki/Precision_and_recall}{precision and recall}. Moreover, their hypergeometric model is particularly interesting, as it presents a novel way to assign a score to a given group of genes $M$, i.e. by evaluating the probability of overlap between the alterations of a specific gene $g \in M$, and the alterations of the remaining ones $M-\{g\}$.

Additionally, \textcite{mutex} mention in their \textit{Discussion} section that they aim to expand their work by exploring \textit{additional topological structures} within the biological network. In fact, their current method focuses on genes with a common downstream target and necessitates that all group members are directly connected in the network without intermediary non-member nodes. However, incorporating linker nodes could facilitate the identification of more distant mutual exclusion relationships \cite{mutex}.

\subsection{Additional considerations}

The methodology presented in this paper lacks clarity, creating significant challenges in understanding their approach. While a preliminary explanation of the algorithm is provided by the authors, \textit{essential details} are omitted, making it difficult to fully comprehend the procedure. The recursive nature of the algorithm further complicates matters, as the simplified overview does not capture its full complexity. To gain a clearer understanding of the methodology, the Java source code provided in the supplementary materials was examined. This analysis helped clarify the underlying processes and the implementation of the algorithm, revealing that the pseudocode included in the paper is a \textbf{significantly simplified} version of the complete algorithm, which contains numerous nuanced aspects.

The description of the \textit{null distribution} estimation proved particularly difficult to interpret. However, after reviewing the source code, it became evident that the process is inherently complex. The \textit{null distributions} are constructed recursively, involving multiple calls to the \texttt{greedyMutex} procedure (described in \cref{greedy_mutex}) and incorporating various constants that dictate the evaluation methods, along with numerous other factors. This complexity highlights the challenge of succinctly explaining such an intricate algorithm, and providing a comprehensive description would fall outside the scope of this work.

As a final note, it is particularly surprising that \textcite{mutex} did not mention a \textit{crucial detail} regarding their approach, which became apparent only after reviewing their source code: in their greedy algorithm, the \texttt{expandGroup} procedure (discussed in \cref{expand_group_mutex}) requires selecting a candidate that is \textit{not only} the best among those in $\delta(M)$, but also \textit{improves the current score} of $M$. The rationale behind this decision is not immediately clear and would benefit from further explanation. This choice implies that Mutex \textbf{does not explore suboptimal solutions}, although incorporating a less optimal candidate could potentially lead to a \textit{better overall solution} at the end of the greedy algorithm.

\section{$\mathrm{C}^3$}

\subsection{The clustering approach}

The algorithm proposed by \textcite{c3} presents a particularly intriguing approach, as applying a \textbf{clustering method} to this problem is not an immediately obvious solution. A potential avenue for further exploration could involve a modified version of the algorithm, where a \textit{single weight} $w$ is assigned to each edge, and a function is introduced to evaluate it, depending on the \textit{trade-off} between $w^-$ and $w^+$. Despite this potential variation, the ILP formulation of the clustering problem is well constructed, and the rounding procedure is intuitively compelling. Their method demonstrates considerable \textit{versatility}, both in terms of the flexibility of cluster sizes and the potential for integration with external data.

\cleardoublepage
